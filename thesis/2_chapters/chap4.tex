% Chapter 4
\chapter{Experimental Results}
\label{chap:result}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 4.1
\section{Star data analysis}

\noindent The main factors affect the runtime of the designed system are:
\begin{itemize}
    \item Image resolution
    \item Number of stars in one image
    \item Star area (in pixels) of one star
\end{itemize}

\noindent If the resolution of the star image is large, the runtime and complexity of the algorithm will increase. Therefore, more optimizations are needed in both the hardware and the software of the system. Number of stars in one image is another aspect that we should consider. Since we need to maintain a disjoint set data structure on hardware, we need to know the maximum and the average number of stars in one image. As shown in Figure~\ref{fig:4_4}, the maximum number of star in one image is 24. Therefore, we should pre-allocate around 50 disjoint sets. We also expect to see an average of 10-11 stars with an average of pixel area around 18-19 pixels over one star as in Figure~\ref{fig:4_5}. This information helps us to pre-allocate the hardware memory BRAM and optimize it if needed. \\  

\noindent The images simulated are based on the SSAO star catalog and the standard ESO star map. Randomized distribution of false stars are added to each image. For each resolution dataset, we have 12530 simulated images. \\

% Figure 4.4
\ntuepsfig[scale=1.0]{4_4}{Number of stars in one image distribution}

% Figure 4.5
\ntuepsfig[scale=1.0]{4_5}{Star area distribution}

\noindent The algorithm runtime performance is then compared between the implementation run on the embedded processor and the application executed on software-hardware co-processing strategy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 4.2
\section{Hardware design}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Components and Design Flow}

The system design are shown in Figure~\ref{fig:4_1}. The IP modules as represented by Xilinx Vivado software are illustrated in Figure~\ref{fig:4_2}. The system includes several components such as:
\begin{itemize}
    \item Processing system.
    \item Centroiding IP core.
    \item Direct Memory Access controlling system.
    \item BRAM
    \item Hardware timer
    \item Interrupt controller
\end{itemize}

% Figure 4.1
\ntuepsfig[width=\textwidth]{4_1}{Hardware design diagram}

\noindent \textbf{Data path} \\
\noindent The pixel data are streamed directly into memory by DMA module. The IP core is designed for processing the centroiding algorithm as soon as the first pixel data arrived. After finishing the centroiding algorithm, the IP core stores the results of centroiding algorithm into BRAM and informs the PS by an interrupt signal. PS then takes the results from BRAM and processes the other stages. The data path is implemented through AXI. \\

\noindent \textbf{Control signals} \\
\noindent The PS and PL side communicate through an interrupt controller. The interrupt controller informs the PS if the centroiding algorithm or hardware timer has finished, informs the DMA controller if the memory is full. The DMA controller then flushes the old data to free the memory. BRAM controller is a dual channel BRAM which is readable from PS side and writable from PL side. \\

% Figure 4.2
\ntuepsfig[width=\textwidth]{4_2}{Hardware design block}

\noindent Table~\ref{tab:resource} shows the percentage of hardware resources used over the available resources from the zedboard. We still have spare resources of the FPGA for other tasks.

% Table 4.1
\begin{ntutab}{|c|c|c|c|}{resource}{Hardware resource consumption}
    \hline
    \textbf{Resource} & \textbf{Used} & \textbf{Available} & \textbf{Percentage (\%)} \\
    \hline
    BRAM\_18K & 17 & 280 & 6.07 \\
    \hline
    DSP48E & 20 & 220 & 9.09 \\
    \hline
    FlipFlops & 9278 & 106400 & 8.72 \\
    \hline
    Lookup Tables & 13387 & 53200 & 25.16 \\
    \hline
\end{ntutab}

% Figure 4.3
% \ntuepsfig[width=\textwidth]{4_3}{Hardware resource consumption}

\newpage \subsection{Power Analysis}

The power consumption of the design is measured based on the condition described in Table~\ref{tab:environment}.

\begin{ntutab}{|c|c|}{environment}{Environment condition}
    \hline
    \textbf{Condition} & \textbf{value} \\
    \hline
    Ambient temperature & $30.0^oC$ \\
    \hline
    Airflow & 250 LFM \\
    \hline
    heat sink & medium \\
    \hline
    board temperature & $25.0^oC$ \\
    \hline
\end{ntutab}

\noindent As in Figure~\ref{fig:power_sum} and Figure~\ref{fig:power}, the Processing System(the ARM A9 processor) consumes 77\% of the power supplied while other hardware components like the IP core, BRAM consume less power. This is due to the fact that generic processors are designed for multiple purpose tasks; hence they are not optimal for power consumption compared to the hardware solution for a specific task.

\ntuepsfig[width=\textwidth]{power_sum}{Power consumption summary}

\ntuepsfig[width=\textwidth]{power}{Power consumption by components}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 4.3
\newpage
\section{Runtime experiments}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%
% subsubsection 4.2.2.1
\subsection{512x512 dataset}

The first dataset is generated by a MATLAB sky simulator software. It simulates the star images captured by the star tracker at specific attitudes. A simulated star tracker is configured as Table~\ref{tab:4_2}. It has $20^o$ field of view (FOV) and can capture the stars that have magnitude threshold Mv less than 5.0. The star camera's attitude is rotated from 0 to $360^o$ right ascension and from $-90^o$ to $90^o$ declinations with an angle increment of $2^o$ to perform a full scan of all the stars from the SAO SKY 2000 star catalogue. The dataset has total 12530 sky images.

% Table 4.2
\begin{ntutab}{|c|c|}{4_2}{Star tracker configuration}
    \hline
    \textbf{Parameters} & \textbf{Value} \\
    \hline
    Field of View (FOV) & $20^o * 20^o$ \\
    \hline
    Visual magnitude threshold & 5.0 \\
    \hline
    Star catalogue & SAO SKY 2000 \\
    \hline
    Number of samples & 12530 \\
    \hline
\end{ntutab}

%%%
\noindent \textbf{A. Software runtime}

\noindent The algorithm is developed on the zedboard processing system which runs on an 1.0 GHz ARM-A9 CPU with 512 MB DDR3 RAM. The algorithm software performance is described in Table~\ref{tab:4_3} and visualized by Figure~\ref{fig:4_6}. The runtime of 4 modules are measured in both average and worst-case over 12530 sky images. \\

\noindent As we know from the profiling stage, the runtime of the centroiding module is the most critical time-consuming part. It can be explained that this stage deals with image processing which is the highest complexity in computation compared to the 3 remaining stages. \\

\noindent Thus, the worstcase runtimes are not far from the averages. This pattern can be explained by the number of stars in one Image and the star area distribution. The distributions are approximately uniform with low standard deviations. Therefore, our system can run stably despite different configuration. \\

\noindent Overall, The average runtime is 17855 us (about 17.86 ms) on each image. 

% Table 4.3
\begin{ntutab}{|c|c|c|}{4_3}{Software runtime}
    \hline
     & \textbf{Average} & \textbf{Worst case} \\
    \hline
    \textbf{Centroiding} & 17688 & 18061 \\
    \hline
    \textbf{Choosing Reference Star} & 54 & 105 \\
    \hline
    \textbf{Finding Star Pattern} & 30 & 109 \\
    \hline
    \textbf{Pattern Matching} & 83 & 155 \\
    \hline
\end{ntutab}

% Figure 4.6
\ntuepsfig[width=\textwidth]{4_6}{Software runtime}

%%%
\newpage
\noindent \textbf{B. Hardware - Software co-processing runtime}

\noindent The algorithm is re-developed on the zedboard in both the processing system(software) and the programmable logic(hardware). The processing system runs on an 1.0 GHz ARM-A9 CPU with 512 MB DDR3 RAM while the programmable logic runs on the FPGA fabric with 100 MHz Clock rate and a total of 560KB BRAM (Block RAM). The algorithm is partitioned into 6 submodules. The first 3 submodules: IP core Initiation, DMA Data Streaming and Centroiding are implemented on the programmable logic side. The 3 remaining submodules: Choosing Reference Star, Finding Star Pattern and Pattern Matching are implemented on the processing system. The system performance is described in Table~\ref{tab:4_4} and visualized by Figure~\ref{fig:4_7}. \\

\noindent The Centroiding software submodule is replaced by 3 equivalent hardware submodules. The runtime is significantly improved from nearly 17 ms to nearly 6.2 ms. \\

\noindent The average total runtime is 6352 us(about 6.35 ms).

% Table 4.4
\begin{ntutab}{|c|c|c|}{4_4}{Hardware – Software Co-processing runtime}
    \hline
     & \textbf{Average} & \textbf{Worst case} \\
    \hline
    \textbf{IP core Initiation} & 6 & 6 \\
    \hline
    \textbf{DMA Data Streaming} & 2460 & 2485 \\
    \hline
    \textbf{Centroiding} & 3719 & 3806 \\
    \hline
    \textbf{Choosing Reference Star} & 54 & 145 \\
    \hline
    \textbf{Finding Star Pattern} & 30 & 109 \\
    \hline
    \textbf{Pattern Matching} & 83 & 155 \\
    \hline
\end{ntutab}

% Figure 4.7
\ntuepsfig[width=\textwidth]{4_7}{Software - Hardware co-processing runtime}


%%%%%%%%%
\newpage \subsection{1024x1024 dataset}

\noindent Next, we perform a study on 1019 star images are captured by the star tracker SST-20S currently mounted on a low earth orbit satellite, VELOX-CI\cite{8374923}. The specifications of the SST-20S star tracker is described by Table~\ref{tab:4_7}.

% Table 4.7
\begin{ntutab}{|c|c|}{4_7}{Specifications of the SST-20S star tracker and the real image\cite{8374923}}
    \hline
    \textbf{Parameter} & Value \\
    \hline
    \textbf{Field of View (FOV)} & $15^o * 15^o$ \\
    \hline
    \textbf{Sensitivity (Mv)} & 6.3 \\
    \hline
    \textbf{Star catalog} & SAO J2000\cite{myers1997sky2000} \\
    \hline
    \textbf{Resolution (w * h)} & 1024 x 1024 pixels \\
    \hline
    \textbf{Pixel size ($\rho$)} & 13 µm \\
    \hline
    \textbf{Focal length (f)} & 50 mm \\
    \hline
    \textbf{Bits per pixel} & 8 \\
    \hline
    \textbf{Position accuracy} & 40 arcsec \\
    \hline
\end{ntutab}

\noindent \textbf{A. Software runtime}

\noindent The algorithm is examined again on the zedboard processing system (1.0 GHz ARM-A9 CPU, 512 MB DDR3 RAM). Its performance is listed in Table~\ref{tab:4_5} and visualized by Figure~\ref{fig:4_8}. The runtime of 4 modules is measured in both average and worst-case over 1019 sky images. \\

\noindent As the image size increased, the runtime of the Centroiding part increases and other module runtimes remain approximately the same. We can explain that the runtime of the centroiding part is proportional to the complexity of the image processing task, while other module complexities depend on the properties of the images which are the number of stars, the brightness of the star catalog threshold. \\

\noindent The average runtime is 70780 us (about 70.78 ms). The runtime has increased 4 times (70 ms compared to 17 ms). \\

% Table 4.5
\begin{ntutab}{|c|c|c|}{4_5}{Software runtime}
    \hline
     & \textbf{Average} & \textbf{Worst case} \\
    \hline
    \textbf{Centroiding} & 70527 & 70561 \\
    \hline
    \textbf{Choosing Reference Star} & 63 & 108 \\
    \hline
    \textbf{Finding Star Pattern} & 54 & 115 \\
    \hline
    \textbf{Pattern Matching} & 136 & 155 \\
    \hline
\end{ntutab}

% Figure 4.8
\ntuepsfig[width=\textwidth]{4_8}{Software runtime}


%%%
\noindent \textbf{B. Hardware - Software Co-processing runtime}

\noindent We again tested the algorithm on the large dataset with the Zedboard System-on-a-chip Processing System and Programmable Logic (PS - PL). The system performance is described in Table~\ref{tab:4_6} and visualized by Figure~\ref{fig:4_9}. \\

\noindent The total runtime of the Centroiding module is around 13.3 ms. Compared to 6.35 ms of the small dataset runtime (512x512), the Hardware-Software Centroiding submodule runtime only increases 2 times. As we look further into each submodule, the DMA Data Streaming submodule runtime has a significant change (2.4 ms to 9.8 ms) while the Centroiding submodule runtime is stable (3.7 ms and 3.5 ms). This can be explained by the hardware design has been proposed and introduced in Chapter 4.2 ``Hardware design''. The DMA Data Streaming submodule streams the image pixels into the system memory, it is the only submodule that affected by the image size complexity. Because the Hardware-Software Centroiding submodule takes the pixel coordinates as inputs, this architecture design helps our system run stably despite the changing of the image size. \\

\noindent The total average runtime is 13636 us (about 13.64 ms).

% Table 4.6
\begin{ntutab}{|c|c|c|}{4_6}{Hardware - Software Co-processing runtime}
    \hline
     & \textbf{Average} & \textbf{Worst case} \\
    \hline
    \textbf{IP core Initiation} & 6 & 6 \\
    \hline
    \textbf{DMA Data Streaming} & 9834 & 9838 \\
    \hline
    \textbf{Centroiding} & 3543 & 3598 \\
    \hline
    \textbf{Choosing Reference Star} & 63 & 108 \\
    \hline
    \textbf{Finding Star Pattern} & 54 & 115 \\
    \hline
    \textbf{Pattern Matching} & 136 & 155 \\
    \hline
\end{ntutab}

% Figure 4.9
\ntuepsfig[width=\textwidth]{4_9}{Hardware - Software Co-processing runtime}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% subsection 4.2.3
\subsection{Runtime Comparison}

Lastly, we perform the final test to compare the runtimes of the 3 classic algorithms and the proposed algorithm by software processing against the proposed algorithm by software-hardware co-processing. The experiment results are benchmarked in Table~\ref{tab:4_7} and visualized by Figure~\ref{fig:4_10}. \\

\noindent The software system is implemented on the zedboard with a 1.0 GHz ARM-A9 CPU and 512 MB DDR3 RAM. The hardware-software co-processing system is executed on the zedboard Processing system -Programmable Logic with a 1.0 GHz ARM-A9 CPU, 512 MB DDR3 RAM (PS) and the FPGA fabric with 100 MHz Clock rate, 560KB BRAM (PL). \\

\noindent The experimental results show that the implementation of the proposed method by software-hardware co-processing has successfully reduced the runtime of the Lost-in-Space star tracking algorithm.

\begin{ntutab}{|c|c|c|}{4_7}{Runtime comparison}
    \hline
     & \textbf{Average(ms)} & \textbf{Worst case(ms)} \\
    \hline
    \textbf{Liebe method SW} & 190.6 & 304.7 \\
    \hline
    \textbf{Geometric voting method SW} & 958.4 & 1044.7 \\
    \hline
    \textbf{Pyramid method SW} & 352.3 & 576.6 \\
    \hline
    \textbf{Proposed method SW} & 70.8 & 70.9 \\
    \hline
    \textbf{Proposed method SW-HW coprocessing} & 13.6 & 13.8 \\
    \hline
\end{ntutab}

\ntuepsfig[width=\textwidth]{4_10}{Runtime comparison}
